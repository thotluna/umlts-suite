# И Implementaci贸n: Capa L茅xica (Lexer)

Este documento detalla los cambios exactos para habilitar los tokens de Perfiles, Estereotipos y Tagged Values.

## 1. Definici贸n de Tokens (`packages/engine/src/syntax/token.types.ts`)

A帽adir los nuevos tipos de tokens al enum `TokenType`:

```typescript
export enum TokenType {
  // ... existentes
  AT = 'AT', // @
  LBRACKET = 'LBRACKET', // [
  RBRACKET = 'RBRACKET', // ]

  // Keywords de Perfiles
  PROFILE = 'PROFILE', // profile
  STEREOTYPE = 'STEREOTYPE', // stereotype
  EXTENDS = 'EXTENDS', // extends

  // Tipos de datos para Tagged Values
  NUMBER = 'NUMBER', // Para Integer/Float
  // ...
}
```

## 2. Configuraci贸n de Matchers (`packages/engine/src/lexer/lexer.factory.ts`)

Registrar los patrones para que el Lexer reconozca los nuevos s铆mbolos y palabras clave:

```typescript
// S铆mbolos unitarios
{ pattern: /^@/, type: TokenType.AT },
{ pattern: /^\[/, type: TokenType.LBRACKET },
{ pattern: /^\]/, type: TokenType.RBRACKET },

// Palabras clave (asegurar que se eval煤en antes que IDENTIFIER)
{ pattern: /^profile\b/, type: TokenType.PROFILE },
{ pattern: /^stereotype\b/, type: TokenType.STEREOTYPE },
{ pattern: /^extends\b/, type: TokenType.EXTENDS },
```

## 3. Gu铆a de Acci贸n

1. **Actualizar `token.types.ts`**: Insertar los nuevos enums.
2. **Actualizar `lexer.factory.ts`**: A帽adir los matchers en el orden de prioridad correcto (keywords antes que identificadores gen茅ricos).
3. **Verificaci贸n**: Ejecutar el lexer con el input `@entity [ table="users" ]` y verificar que genera la secuencia: `AT`, `IDENTIFIER`, `LBRACKET`, `IDENTIFIER`, `EQUALS`, `STRING`, `RBRACKET`.
